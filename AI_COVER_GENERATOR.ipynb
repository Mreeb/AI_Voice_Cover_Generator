{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "AnkNtxzufOmq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mreeb/AI_Voice_Cover_Generator/blob/master/AI_COVER_GENERATOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import os\n",
        "source = \"Rejekts\"\n",
        "!wget https://huggingface.co/{source}/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip -n '/content/project-main.zip' -d '/content/'\n",
        "!cd '/content/project-main' && python download_files.py && pip install -r 'requirements-safe.txt'\n",
        "!pip install pyngrok tensorflow==2.12.0\n",
        "!rm '/content/project-main.zip'\n",
        "!rm -r '/content/sample_data'\n",
        "!mkdir -p '/content/dataset'\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Success\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "788lbAl8-R8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/project-main\n",
        "model_name = 'Vegeta'#---------------------------------------------------\n",
        "dataset_folder = '/content/Ali' #-------------------------------------\n",
        "while len(os.listdir(dataset_folder)) < 1:\n",
        "    input(\"Your dataset folder is empty.\")\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n",
        "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")"
      ],
      "metadata": {
        "id": "w4wXvoez9Rce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f0method = \"rmvpe_gpu\"\n",
        "%cd /content/project-main\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "if f0method != \"rmvpe_gpu\":\n",
        "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
        "else:\n",
        "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your data was preprocessed.\")"
      ],
      "metadata": {
        "id": "G0MEhFM19Vq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "%cd /content/project-main\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"请先进行特征提取!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"请先进行特征提取！\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=10000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * config.n_cpu,\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            logger.info(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"training\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)  #\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"adding\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if 'adding' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"
      ],
      "metadata": {
        "id": "3KyMRbK49g__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "K9edc1lD8_8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Release GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8IRV85Jr9Bat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/project-main\n",
        "from random import shuffle\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "now_dir=os.getcwd()\n",
        "model_name = 'Vegeta'\n",
        "save_frequency = 10\n",
        "epochs = 100\n",
        "cache = False\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    print(\"Write filelist done\")\n",
        "    print(\"Use gpus:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pretrained Generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pretrained Discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = \"configs/v1/%s.json\" % sr2\n",
        "    else:\n",
        "        config_path = \"configs/v2/%s.json\" % sr2\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "    p.wait()\n",
        "    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n",
        "try:\n",
        "    training_log = click_train(\n",
        "        model_name,\n",
        "        '40k',\n",
        "        True,\n",
        "        0,\n",
        "        save_frequency,\n",
        "        epochs,\n",
        "        12,\n",
        "        True,\n",
        "        'assets/pretrained_v2/f0G40k.pth',\n",
        "        'assets/pretrained_v2/f0D40k.pth',\n",
        "        0,\n",
        "        cache,\n",
        "        True,\n",
        "        'v2',\n",
        "    )\n",
        "    print(training_log)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "FFfC9x239kC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE THIS CODE WHEN YOU HAVE ALREADY TRAINED A VOICE MODEL USING ABOVE CELLS"
      ],
      "metadata": {
        "id": "vbdToNPeUQ1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SociallyIneptWeeb/AICoverGen.git\n",
        "%cd AICoverGen\n",
        "!pip install -q -r requirements.txt\n",
        "!sudo apt update\n",
        "!sudo apt install sox\n",
        "!python src/download_models.py"
      ],
      "metadata": {
        "id": "02652iQGx5td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IF FROM A LINK"
      ],
      "metadata": {
        "id": "AnkNtxzufOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import urllib.request\n",
        "\n",
        "BASE_DIR = os.getcwd()\n",
        "rvc_models_dir = os.path.join(BASE_DIR, 'rvc_models')\n",
        "\n",
        "def extract_zip(extraction_folder, zip_name):\n",
        "    os.makedirs(extraction_folder)\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_folder)\n",
        "    os.remove(zip_name)\n",
        "\n",
        "    index_filepath, model_filepath = None, None\n",
        "    for root, dirs, files in os.walk(extraction_folder):\n",
        "        for name in files:\n",
        "            if name.endswith('.index') and os.stat(os.path.join(root, name)).st_size > 1024 * 100:\n",
        "                index_filepath = os.path.join(root, name)\n",
        "\n",
        "            if name.endswith('.pth') and os.stat(os.path.join(root, name)).st_size > 1024 * 1024 * 40:\n",
        "                model_filepath = os.path.join(root, name)\n",
        "\n",
        "    if not model_filepath:\n",
        "        raise Exception(f'No .pth model file was found in the extracted zip. Please check {extraction_folder}.')\n",
        "\n",
        "    os.rename(model_filepath, os.path.join(extraction_folder, os.path.basename(model_filepath)))\n",
        "    if index_filepath:\n",
        "        os.rename(index_filepath, os.path.join(extraction_folder, os.path.basename(index_filepath)))\n",
        "\n",
        "    for filepath in os.listdir(extraction_folder):\n",
        "        if os.path.isdir(os.path.join(extraction_folder, filepath)):\n",
        "            shutil.rmtree(os.path.join(extraction_folder, filepath))\n",
        "\n",
        "def download_online_model(url, dir_name):\n",
        "    try:\n",
        "        print(f'[~] Downloading voice model with name {dir_name}...')\n",
        "        zip_name = url.split('/')[-1]\n",
        "        extraction_folder = os.path.join(rvc_models_dir, dir_name)\n",
        "        if os.path.exists(extraction_folder):\n",
        "            raise Exception(f'Voice model directory {dir_name} already exists! Choose a different name for your voice model.')\n",
        "\n",
        "        if 'pixeldrain.com' in url:\n",
        "            url = f'https://pixeldrain.com/api/file/{zip_name}'\n",
        "\n",
        "        urllib.request.urlretrieve(url, zip_name)\n",
        "\n",
        "        print('[~] Extracting zip...')\n",
        "        extract_zip(extraction_folder, zip_name)\n",
        "        print(f'[+] {dir_name} Model successfully downloaded!')\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))\n",
        "\n",
        "url = \"https://pixeldrain.com/u/rx5eSf1K\" #----------------\n",
        "dir_name = \"Vegeta\" #------------------\n",
        "\n",
        "download_online_model(url, dir_name)"
      ],
      "metadata": {
        "id": "n2E7S7VwyOsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a Model Folder"
      ],
      "metadata": {
        "id": "twIPsTuTfSwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model_name = \"Vegeta\" # Model Name -----------------\n",
        "os.makedirs(f\"/content/AICoverGen/rvc_models/{model_name}\", exist_ok=True)"
      ],
      "metadata": {
        "id": "EYSdqYo4e9QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "zip_file_path = f\"/content/{model_name}.zip\"\n",
        "extracted_folder_path = f\"/content/AICoverGen/rvc_models/{model_name}\"\n",
        "os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "if os.path.exists(extracted_folder_path):\n",
        "    print(f\"Contents of '{zip_file_path}' extracted successfully to '{extracted_folder_path}'.\")\n",
        "else:\n",
        "    print(f\"Failed to extract contents of '{zip_file_path}' to '{extracted_folder_path}'.\")"
      ],
      "metadata": {
        "id": "111bWSevU_Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENERATE COVER"
      ],
      "metadata": {
        "id": "tqPSfdtDhGzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SONG_INPUT = \"/content/SONG_INPUT/WhatsApp-Ptt-2023-11-28-at-1.57.34-AM.mp3\"\n",
        "SONG_INPUT = \"https://youtu.be/k4yXQkG2s1E?si=e1F54kX34q8VUzoI\" # Change Song Here ---------------------\n",
        "RVC_DIRNAME = model_name\n",
        "PITCH_CHANGE = 0\n",
        "PITCH_CHANGE_ALL = 0\n",
        "INDEX_RATE = 0.5\n",
        "FILTER_RADIUS = 3\n",
        "PITCH_DETECTION_ALGO = \"rmvpe\"\n",
        "CREPE_HOP_LENGTH = 128\n",
        "PROTECT = 0.33\n",
        "REMIX_MIX_RATE = 0.25\n",
        "MAIN_VOL = 0\n",
        "BACKUP_VOL = 0\n",
        "INST_VOL = 0\n",
        "\n",
        "REVERB_SIZE = 0.15\n",
        "REVERB_WETNESS = 0.2\n",
        "REVERB_DRYNESS = 0.8\n",
        "REVERB_DAMPING = 0.7\n",
        "OUTPUT_FORMAT = \"mp3\"\n",
        "\n",
        "import subprocess\n",
        "\n",
        "command = [\n",
        "    \"python\",\n",
        "    \"src/main.py\",\n",
        "    \"-i\", SONG_INPUT,\n",
        "    \"-dir\", RVC_DIRNAME,\n",
        "    \"-p\", str(PITCH_CHANGE),\n",
        "    \"-k\",\n",
        "    \"-ir\", str(INDEX_RATE),\n",
        "    \"-fr\", str(FILTER_RADIUS),\n",
        "    \"-rms\", str(REMIX_MIX_RATE),\n",
        "    \"-palgo\", PITCH_DETECTION_ALGO,\n",
        "    \"-hop\", str(CREPE_HOP_LENGTH),\n",
        "    \"-pro\", str(PROTECT),\n",
        "    \"-mv\", str(MAIN_VOL),\n",
        "    \"-bv\", str(BACKUP_VOL),\n",
        "    \"-iv\", str(INST_VOL),\n",
        "    \"-pall\", str(PITCH_CHANGE_ALL),\n",
        "    \"-rsize\", str(REVERB_SIZE),\n",
        "    \"-rwet\", str(REVERB_WETNESS),\n",
        "    \"-rdry\", str(REVERB_DRYNESS),\n",
        "    \"-rdamp\", str(REVERB_DAMPING),\n",
        "    \"-oformat\", OUTPUT_FORMAT\n",
        "]\n",
        "\n",
        "# Open a subprocess and capture its output\n",
        "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
        "\n",
        "# Print the output in real-time\n",
        "for line in process.stdout:\n",
        "    print(line, end='')\n",
        "\n",
        "# Wait for the process to finish\n",
        "process.wait()"
      ],
      "metadata": {
        "id": "GVyCYGyRyQLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3SvUVLsaYNT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}